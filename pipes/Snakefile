configfile: "config.json"

include: config["binDir"]+"/pipes/rules/demux.rules"
include: config["binDir"]+"/pipes/rules/hs_deplete.rules"
include: config["binDir"]+"/pipes/rules/assembly.rules"
include: config["binDir"]+"/pipes/rules/interhost.rules"
include: config["binDir"]+"/pipes/rules/reports.rules"

def read_samples_file(fname):
    with open(fname, 'rt') as inf:
        for line in inf:
            yield line.strip()

rule all:
    input:
        # create final assemblies for all samples
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
        # create BAMs of aligned reads to own consensus and to common ref
        expand("{dataDir}/{subdir}/{sample}.bam",
            dataDir=config["dataDir"], subdir=config["subdirs"]["align_self"],
            sample=read_samples_file(config["samples_assembly"])),
        # create reference-guided analyses of diversity (quick outputs)
        os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.fasta'),
        os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.vcf.gz'),
        # create summary reports
        config["reportsDir"]+'/summary.coverage_ref.txt.gz',
        config["reportsDir"]+'/summary.coverage_self.txt.gz',
        config["reportsDir"]+'/summary.fastqc.txt',
        config["reportsDir"]+'/summary.bamstats.txt',
        config["reportsDir"]+'/summary.spike_count.txt'
    params: LSF="-N"
    run:
            if "job_profiler" in config:
                print("running report on all job runs")
                shell("{config[job_profiler]} {config[logDir]} {config[reportsDir]}/summary.job_stats.txt")
            print("echo all done!")

rule all_demux_basecalls:
    input:  all_basecalls_inputs
    params: LSF="-N"
    run:
            print("echo all done!")

rule all_demux_merge:
    input:
            expand("{dir}/{lib}.bam",
                dir = os.path.join(config['dataDir'], config['subdirs']['source']),
                lib=get_all_libraries(config['seqruns_demux'])),
    params: LSF="-N"
    run:
            print("echo all done!")

rule all_deplete:
    input:
        expand("{dataDir}/{subdir}/{sample}.{adjective}.bam",
            dataDir=config["dataDir"],
            subdir=config["subdirs"]["depletion"],
            adjective=['raw','cleaned'],
            sample=read_samples_file(config["samples_depletion"])),
    params: LSF="-N"

rule all_assemble:
    input:
        # create final assemblies for all samples
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
        # create BAMs of aligned reads to own consensus
        expand("{dataDir}/{subdir}/{sample}.bam",
            dataDir=config["dataDir"], subdir=config["subdirs"]["align_self"],
            sample=read_samples_file(config["samples_assembly"]))

rule all_reports:
    input:
        config["reportsDir"]+'/summary.coverage_ref.txt.gz',
        config["reportsDir"]+'/summary.coverage_self.txt.gz',
        config["reportsDir"]+'/summary.fastqc.txt',
        config["reportsDir"]+'/summary.bamstats.txt',
        config["reportsDir"]+'/summary.spike_count.txt'
    params: LSF="-N"

rule clean:
    params: LSF="-N"
    shell: "rm -rf {config[tmpDir]}/* .snakemake.tmp.*"
