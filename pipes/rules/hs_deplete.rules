"""
    This is a basic framework for depleting human and other contaminant 
    reads from NGS data.  All non-human reads should remain behind.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>'

configfile: "config.json"


rule all_deplete:
    # these are the final desired output files from this pipeline
    input:  expand("{dataDir}/{sample}.{adjective}.bam", dataDir=config["dataDir"], sample=config["samples"], adjective=["cleaned", "bmtagger_depleted"])

rule bam_to_fastq:
    input:  config["dataDir"]+'/{sample,\w+}.bam'
    output: config["tmpDir"]+ '/{sample}.raw.1.fastq', 
            config["tmpDir"]+ '/{sample}.raw.2.fastq', 
            config["tmpDir"]+ '/{sample}.raw.samheader.txt'
    params: LSF='', JVM='-Xmx2g'
    # TODO: replace with python wrapper command
    run:
            shell("java {params.JVM} -jar {config[picardDir]}/SamToFastq.jar INPUT={input} FASTQ={output}[0] SECOND_END_FASTQ={output}[1] VALIDATION_STRINGENCY=SILENT")
            shell("{config[samtoolsDir]}/samtools view -H {input} > {output}[2]")

rule deplete_bmtagger:
    input:  '{basename}.raw.1.fastq', '{basename}.raw.2.fastq'
    output: '{basename}.bmtagger_depleted.1.fastq', '{basename}.bmtagger_depleted.2.fastq'
    params: LSF='-W 4:00',
            refDbs = expand("{dir}/{db}", dir=config["bmTaggerDbDir"], db=config["bmTaggerDbs_remove"])
    shell:  "{config[binDir]}/taxon_filter.py partition_bmtagger {input} {params.refDbs} --outNoMatch {output}"

rule rmdup_mvicuna:
    input:  '{basename}.bmtagger_depleted.1.fastq', '{basename}.bmtagger_depleted.2.fastq'
    output: '{basename}.rmdup.1.fastq', '{basename}.rmdup.2.fastq'
    params: LSF='-W 4:00 -R "rusage[mem=8]"'
    shell:  "{config[binDir]}/taxon_filter.py dup_remove_mvicuna {input} {output}"

rule split_reads:
    input:  '{basename}.rmdup.{direction}.fastq'
    output: dynamic('{basename}.blast_split_input.{direction}.{split_id}')
    params: LSF='', length='10000'
    shell:  "split -a 3 -l {params.length} {input} {wildcards.basename}.blast_input.{wildcards.direction}."

rule blastn_deplete:
    input:  '{basename}.blast_split_input.1.{split_id}',
            '{basename}.blast_split_input.2.{split_id}'
    output: '{basename}.blast_split_output.1.{split_id}',
            '{basename}.blast_split_output.2.{split_id}'
    params: LSF='-q week',
            refDbs='{config[blastDbDir]}/{config[blastDb_remove]}'
    shell:  "{config[binDir]}/taxon_filter.py deplete_blastn {input} {output} {params.refDbs}"

rule cat_reads:
    input:  dynamic('{basename}.blast_split_output.{direction}.{split_id}')
    output: '{basename}.blast_depleted.{direction,[12]}.fastq'
    params: LSF=""
    shell:  "cat {input} > {output}"

rule fastq_matepair_fix:
    input:  '{basename}.blast_depleted.1.fastq', '{basename}.blast_depleted.2.fastq'
    output: '{basename}.cleaned.1.fastq', '{basename}.cleaned.2.fastq',
            temp('{basename}.cleaned.unpaired.fastq')
    params: LSF=''
    # TODO: replace with python wrapper command
    shell:  "{config[binDir]}/scripts/mergeShuffledFastqSeqs.pl -t -r '^@(\S+)/[1|2]$' -f1 {input}[0] -f2 {input}[1] -o {output}[0][:-8]"

rule fastq_to_bam:
    input:  config["tmpDir"] +'/{sample}.{adjective}.1.fastq',
            config["tmpDir"] +'/{sample}.{adjective}.2.fastq',
            config["tmpDir"] +'/{sample}.raw.samheader.txt'
    output: config["dataDir"]+'/{sample,\w+}.{adjective,\w+}.bam',
            config["dataDir"]+'/{sample}.{adjective}.badheader.bam'
    # TODO: replace with python wrapper command
    params: LSF='', JVM='-Xmx2g'
    run:
            shell("java {params.JVM} -jar {config[picardDir]}/FastqToSam.jar FASTQ={input}[0] FASTQ2={input}[1] OUTPUT={output}[1] SAMPLE_NAME={sample} SORT_ORDER=unsorted")
            shell("{config[samtoolsDir]}/samtools reheader {input}[2] {output}[1] > {output}[0]")
