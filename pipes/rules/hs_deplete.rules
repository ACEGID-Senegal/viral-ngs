"""
    This is a basic framework for depleting human and other contaminant 
    reads from NGS data.  All non-human reads should remain behind.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>'

from snakemake.utils import makedirs
import os

rule revert_bam:
    input:  config["dataDir"]+'/'+config["subdirs"]["source"]+'/{sample}.bam'
    output: config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.raw.bam'
    params: LSF='-M 12 -R "rusage[mem=6]" -W 4:00',
            logid="{sample}"
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["dataDir"],config["tmpDir"]],
                subdir=config["subdirs"]["depletion"]))
            shell("{config[binDir]}/read_utils.py revert_bam_picard {input} {output} --picardOptions SORT_ORDER=queryname SANITIZE=true")

rule split_bam:
    input:  config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.raw.bam'
    output: expand('{dir}/{{sample}}.raw.{split_id:03d}.bam', \
    			dir = config["tmpDir"] + '/' + config["subdirs"]["depletion"], \
                split_id = range(1,1+config["deplete_bmtagger_nchunks"]))
    params: LSF='-M 6 -R "rusage[mem=3]" -W 4:00',
            logid="{sample}"
    shell:	"{config[binDir]}/read_utils.py split_bam {input} {output}"

rule deplete_bmtagger:
    input:  '{dir}/{sample}.raw.{split_id}.bam'
    #       expand("{dbdir}/{db}.{suffix}",
    #           dbdir=config["bmTaggerDbDir"],
    #           db=config["bmTaggerDbs_remove"],
    #           suffix=["bitmask","srprism.idx","srprism.map"])
    output: '{dir}/{sample}.bmtagger_depleted.{split_id,\d+}.bam'
    params: LSF='-W 4:00 -M 16 -R "rusage[mem=8]" -sp 40',
            refDbs = expand("{dbdir}/{db}", dbdir=config["bmTaggerDbDir"], db=config["bmTaggerDbs_remove"]),
            logid="{sample}-{split_id}"
    shell:  "{config[binDir]}/taxon_filter.py deplete_bam_bmtagger {input} {params.refDbs} {output}"

rule rmdup_mvicuna_split:
    input:
            expand('{{dir}}/{{sample}}.bmtagger_depleted.{split_id:03d}.bam',
                split_id = range(1,1+config["deplete_bmtagger_nchunks"]))
    output: 
            expand('{{dir}}/{{sample}}.rmdup.{split_id:03d}.bam',
                split_id = range(1,1+config["deplete_blast_nchunks"]))
    params:
            LSF='-W 4:00 -M 16 -R "rusage[mem=8]" -sp 75',
            logid="{sample}",
            tmpf_input = '{dir}/{sample}.bmtagger_depleted.bam',
            tmpf_output = '{dir}/{sample}.rmdup.bam'
    run:
            shell("{config[binDir]}/read_utils.py merge_bams {input} {params.tmpf_input}")
            shell("{config[binDir]}/read_utils.py rmdup_mvicuna_bam {params.tmpf_input} {params.tmpf_output}")
            shell("{config[binDir]}/read_utils.py split_bam {params.tmpf_output} {output}")
            os.unlink(params.tmpf_input)
            os.unlink(params.tmpf_output)

rule deplete_blastn_paired:
    input:  '{dir}/{sample}.rmdup.{split_id}.bam'
    output: '{dir}/{sample}.cleaned.{split_id,\d+}.bam'
    params: LSF='-W 4:00 -M 16 -R "rusage[mem=8]" -sp 40',
            refDbs = expand("{dbdir}/{db}", dbdir=config["blastDbDir"], db=config["blastDb_remove"]),
            logid="{sample}-{split_id}"
    shell:  "{config[binDir]}/taxon_filter.py deplete_blastn_bam {input} {params.refDbs} {output}"

rule merge_to_clean_bam:
    input:
    	    expand('{dir}/{{sample}}.cleaned.{split_id:03d}.bam',
                dir = config["tmpDir"]+'/'+config["subdirs"]["depletion"],
                split_id = range(1,1+config["deplete_blast_nchunks"]))
    output: config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.cleaned.bam'
    params: LSF='-M 6 -R "rusage[mem=3]"',
            logid="{sample}"
    shell:	"{config[binDir]}/read_utils.py merge_bams {input} {output}"
