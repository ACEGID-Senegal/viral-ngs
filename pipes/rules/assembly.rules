"""
    This is a basic framework for assembly of viral genomes, currently
    tailored for EBOV. Some generalization work needed to expand this
    to generic viral genomes with an arbitrary number of segments/chromosomes.
    
    note: all this runs in ~3hrs, no step takes more than 4GB RAM, and the
    DAG is linear per sample, so we could conslidate most of this into a
    single Bellini-like script (once we actually Tool-ify all of the critical
    pieces like Trinity, MOSIAK, VFAT, Novoalign, GATK)
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time, shutil


rule all_assemble:
    input:
        # create final assemblies for all samples
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
        # create BAMs of aligned reads to own consensus
        expand("{dataDir}/{subdir}/{sample}.bam",
            dataDir=config["dataDir"], subdir=config["subdirs"]["align_self"],
            sample=read_samples_file(config["samples_assembly"]))
    params: LSF="-N"

rule all_assemble_failures:
    input:
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config.get("samples_assembly_failures"))),
    params: LSF="-N"



rule assemble_trinity:
    ''' This step runs the Trinity assembler.
        First trim reads with trimmomatic, rmdup with prinseq,
        and random subsample to no more than 100k reads.
    '''
    input:  config["dataDir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.taxfilt.bam'
    output: config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.subsamp.bam'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            n_reads="100000",
            logid="{sample}",
            clipDb=config["trim_clipDb"]
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["dataDir"],config["tmpDir"]],
                subdir=config["subdirs"]["assembly"]))
            shell("{config[binDir]}/assembly.py assemble_trinity {input} {params.clipDb} {output[0]} --n_reads={params.n_reads} --outReads {output[1]}")

rule orient_and_impute:
    ''' This step cleans up the Trinity assembly with a known reference genome.
        VFAT (maybe Bellini later): take the Trinity contigs, align them to
            the known reference genome, switch it to the same strand as the
            reference, and produce chromosome-level assemblies (with runs of
            N's in between the Trinity contigs).
        filter_short_seqs: We then toss out all assemblies that come out to
            < 15kb or < 95% unambiguous and fail otherwise.
        modify_contig: Finally, we trim off anything at the end that exceeds
            the length of the known reference assembly.  We also replace all
            Ns and everything within 55bp of the chromosome ends with the
            reference sequence.  This is clearly incorrect consensus sequence,
            but it allows downstream steps to map reads in parts of the genome
            that would otherwise be Ns, and we will correct all of the inferred
            positions with two steps of read-based refinement (below), and
            revert positions back to Ns where read support is lacking.
    '''
    input:  config["tmpDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity.fasta',
            config["tmpDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.subsamp.bam'
    output: config["tmpDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-vfat.fasta',
            config["tmpDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.fasta'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            refGenome=config["ref_genome"],
            length = str(config["assembly_min_length"][0]),
            min_unambig = str(config["assembly_min_unambig"]),
            renamed_prefix="",
            replace_length="55",
            logid="{sample}"
    run:
            shell("{config[binDir]}/assembly.py order_and_orient {input[0]} {params.refGenome} {output[0]} --inReads {input[1]}")
            shell("{config[binDir]}/assembly.py impute_from_reference {output[0]} {params.refGenome} {output[1]} --newName {params.renamed_prefix}{wildcards.sample} --replaceLength {params.replace_length} --minLength {params.length} --minUnambig {params.min_unambig}")

rule refine_assembly_1:
    ''' This a first pass refinement step where we take the VFAT assembly,
        align all reads back to it, and modify the assembly to the majority
        allele at each position based on read pileups.
        This step now considers both SNPs as well as indels called by GATK
        and will correct the consensus based on GATK calls.
        Reads are aligned with Novoalign with permissive mapping thresholds,
        then PCR duplicates are removed with Picard (in order to debias the
        allele counts in the pileups), and realigned with GATK's
        IndelRealigner (in order to call indels).
        Output FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.fasta',
            config["dataDir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.vcf.gz'
    resources: mem=4
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="{sample}",
            novoalign_options = "-r Random -l 30 -g 40 -x 20 -t 502",
            min_coverage = "2"
    shell:  "{config[binDir]}/assembly.py refine_assembly {input} {output[0]} --outVcf {output[1]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}'"

rule refine_assembly_2:
    ''' This a second pass refinement step very similar to the first.
        The only differences are that Novoalign mapping parameters are
        more conservative and the input consensus sequence has already
        been refined once and the input reads are the full raw read
        set (instead of the cleaned read set). We also require higher
        minimum read coverage (3 instead of 2) in order to call a
        non-ambiguous base.
        The output of this step is the final assembly for this sample.
        Final FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
            config["dataDir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.raw.bam'
    output: config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.vcf.gz'
    resources: mem=4
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="{sample}",
            novoalign_options = "-r Random -l 40 -g 40 -x 20 -t 100",
            min_coverage = "3"
    shell:  "{config[binDir]}/assembly.py refine_assembly {input} {output[0]} --outVcf {output[1]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}'"

rule map_reads_to_self:
    ''' After the final assembly is produced, we also produce BAM files with all reads
        mapped back to its own consensus.  Outputs several BAM files, sorted and indexed:
            {sample}.bam           - all raw reads
            {sample}.mapped.bam    - only mapped reads
            {sample}.rmdup.bam     - only mapped reads, with duplicates removed by Picard
            {sample}.realigned.bam - mapped/rmdup reads, realigned with GATK IndelRealigner
    '''
    input:  config["dataDir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam',
            config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
    output: config["dataDir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.bam',
            config["dataDir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.mapped.bam'
    resources: mem=4
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="{sample}",
            novoalign_options = "-r Random -l 40 -g 40 -x 20 -t 100 -k -c 3"
    run:
            makedirs(os.path.join(config["dataDir"], config["subdirs"]["align_self"]))
            shell("{config[binDir]}/read_utils.py align_and_fix {input} --outBamAll {output[0]} --outBamFiltered {output[1]} --novoalign_options '{params.novoalign_options}'")
