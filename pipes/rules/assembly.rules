"""
    This is a basic framework for assembly of viral genomes, currently
    tailored for EBOV. Some generalization work needed to expand this
    to generic viral genomes with an arbitrary number of segments/chromosomes.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time, shutil


rule all_assemble:
    input:
        # create final assemblies for all samples
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
        # create BAMs of aligned reads to own consensus
        expand("{dataDir}/{subdir}/{sample}.bam",
            dataDir=config["dataDir"], subdir=config["subdirs"]["align_self"],
            sample=read_samples_file(config["samples_assembly"]))
    params: LSF="-N"

rule all_assemble_failures:
    input:
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config.get("samples_assembly_failures"))),
    params: LSF="-N"

def merge_one_per_sample_inputs(wildcards):
    if 'seqruns_demux' not in config or not os.path.isfile(config['seqruns_demux']):
        return "unreachable/" + wildcards.sample + '.' + wildcards.adjective + '.bam'
    libs = set()
    for flowcell in read_samples_file(config['seqruns_demux']):
        for lane in read_tab_file(flowcell):
            for well in read_tab_file(lane['barcode_file']):
                if well['sample'] == wildcards.sample:
                    libs.add(os.path.join(config["dataDir"], config["subdirs"]["depletion"],
                        well['sample'] + '.l' + well['library_id_per_sample'] + '.' + wildcards.adjective + '.bam'))
    return sorted(libs)
rule merge_one_per_sample:
    input:  merge_one_per_sample_inputs
    output: config["dataDir"]+'/'+config["subdirs"]["depletion"] +'/{sample}.{adjective,\w+}.bam'
    resources: mem=2
    params: logid="{sample}"
    shell:  "{config[binDir]}/read_utils.py merge_bams {input} {output} --picardOptions SORT_ORDER=queryname"

rule trim_reads:
    ''' Since Trinity operates on fastq input, it cannot see the clipping
        information in the BAM files, so we must clip adapter sequences
        manually.
    '''
    input:  config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.cleaned.bam'
    output: config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.trimmed.1.fastq', 
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.trimmed.2.fastq'
    resources: mem=3
    params: logid="{sample}",
            tmpf_fastq = [
                config["tmpDir"] +'/'+config["subdirs"]["assembly"] +'/{sample}.cleaned.1.fastq',
                config["tmpDir"] +'/'+config["subdirs"]["assembly"] +'/{sample}.cleaned.2.fastq'],
            clipDb=config["trim_clipDb"]
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["dataDir"],config["tmpDir"]],
                subdir=config["subdirs"]["assembly"]))
            shell("{config[binDir]}/read_utils.py bam_to_fastq {input} {params.tmpf_fastq}")
            shell("{config[binDir]}/taxon_filter.py trim_trimmomatic {params.tmpf_fastq} {output} {params.clipDb}")

rule filter_to_taxon:
    ''' This step reduces the read set to a specific taxon (usually the genus
        level or greater for the virus of interest).
        Additionally, this step also runs a prinseq-based duplicate removal.
    '''
    input:  '{dir}/{sample}.trimmed.{direction}.fastq'
    output: '{dir}/{sample}.filtered.{direction,[12]}.fastq'
    resources: mem=12
    params: LSF='-W 4:00',
            refDbs=config["lastal_refDb"],
            logid="{sample}-{direction}"
    shell:  "{config[binDir]}/taxon_filter.py filter_lastal {input} {params.refDbs} {output}"

rule fix_lastal_output:
    input:  '{dir}/{sample}.filtered.1.fastq',
            '{dir}/{sample}.filtered.2.fastq'
    output: '{dir}/{sample}.filtered.fix.1.fastq',
            '{dir}/{sample}.filtered.fix.2.fastq'
    resources: mem=3
    params: logid="{sample}"
    shell:  "{config[binDir]}/read_utils.py purge_unmated {input} {output}"

rule assemble_trinity:
    ''' This step runs the Trinity assembler on no more than 100k reads (random
        subsample if necessary).
    '''
    input:  '{dir}/{sample}.filtered.fix.1.fastq',
            '{dir}/{sample}.filtered.fix.2.fastq'
    output: '{dir}/{sample}.assembly1-trinity.fasta'
    resources: mem=4
    params: n_reads="100000",
            logid="{sample}",
            tmpf_subsamp=['{dir}/{sample}.filtered.fix.sub.1.fastq',
                '{dir}/{sample}.filtered.fix.sub.2.fastq'],
            tmpd_trinity='{dir}/{sample}.trinity'
    #shell:  "{config[binDir]}/assembly.py assemble_trinity {input} {output}"
    run:
            shutil.rmtree(params.tmpd_trinity, ignore_errors=True)
            shell("{config[binDir]}/tools/scripts/subsampler.py -n {params.n_reads} -mode p -in {input} -out {params.tmpf_subsamp}")
            shell("reuse -q Java-1.6 && perl /idi/sabeti-scratch/kandersen/bin/trinity_old/Trinity.pl --CPU 1 --min_contig_length 300 --seqType fq --left {params.tmpf_subsamp[0]} --right {params.tmpf_subsamp[1]} --output {params.tmpd_trinity}")
            shutil.copyfile(params.tmpd_trinity+"/Trinity.fasta", output[0])
            map(os.unlink, params.tmpf_subsamp)
            shutil.rmtree(params.tmpd_trinity, ignore_errors=True)

def first_fasta_header(inFasta):
    # this method can go away when align_and_orient gets turned into a script
    with open(inFasta, 'rt') as inf:
        return inf.readline().rstrip('\n').lstrip('>')

rule align_and_orient:
    ''' This step cleans up the Trinity assembly with a known reference genome.
        VFAT (maybe Bellini later): take the Trinity contigs, align them to
            the known reference genome, switch it to the same strand as the
            reference, and produce chromosome-level assemblies (with runs of
            N's in between the Trinity contigs).
        filter_short_seqs: We then toss out all assemblies that come out to
            < 15kb or < 95% unambiguous and fail otherwise.
        modify_contig: Finally, we trim off anything at the end that exceeds
            the length of the known reference assembly.  We also replace all
            Ns and everything within 55bp of the chromosome ends with the
            reference sequence.  This is clearly incorrect consensus sequence,
            but it allows downstream steps to map reads in parts of the genome
            that would otherwise be Ns, and we will correct all of the inferred
            positions with two steps of read-based refinement (below), and
            revert positions back to Ns where read support is lacking.
    '''
    input:  '{dir}/{sample}.assembly1-trinity.fasta',
            '{dir}/{sample}.filtered.fix.1.fastq',
            '{dir}/{sample}.filtered.fix.2.fastq'
    output: '{dir}/{sample}.assembly2-vfat.fasta',
            '{dir}/{sample}.assembly3-modify.fasta'
    resources: mem=3
    params: refGenome=config["ref_genome"],
            length = str(config["assembly_min_length"][0]),
            min_unambig = str(config["assembly_min_unambig"]),
            renamed_prefix="EBOV_2014_",
            replace_length="55",
            logid="{sample}",
            tmpf_prefix='{dir}/{sample}.assembly1.5',
            tmpf_muscle='{dir}/{sample}.muscle_align.fasta'
    run:
            update_timestamps(input)
            shell("touch {params.tmpf_prefix}_dummy && rm -rf {params.tmpf_prefix}*")
            shell("touch {params.tmpf_prefix}_merger_assembly.fa")
            shell("{config[binDir]}/tools/scripts/vfat/orientContig.pl {input[0]} {params.refGenome} {params.tmpf_prefix}")
            shell("{config[binDir]}/tools/scripts/vfat/contigMerger.pl {params.tmpf_prefix}_orientedContigs {params.refGenome} -readfq {input[1]} -readfq2 {input[2]} -fakequals 30 {params.tmpf_prefix}")
            shell("cat {params.tmpf_prefix}*assembly.fa > {params.tmpf_prefix}_prefilter.fasta")
            
            shell("{config[binDir]}/assembly.py filter_short_seqs {params.tmpf_prefix}_prefilter.fasta {params.length} {params.min_unambig} {output[0]}")
            assert_nonempty_file(output[0])
            shell("rm -rf {params.tmpf_prefix}*")
            
            shell("cat {output[0]} {params.refGenome} | /idi/sabeti-scratch/kandersen/bin/muscle/muscle -out {params.tmpf_muscle} -quiet")
            refName = first_fasta_header(params.refGenome)
            shell("{config[binDir]}/assembly.py modify_contig {params.tmpf_muscle} {output[1]} {refName} --name {params.renamed_prefix}{wildcards.sample} --call-reference-ns --trim-ends --replace-5ends --replace-3ends --replace-length {params.replace_length} --replace-end-gaps")
            assert_nonempty_file(output[1])
            index_novoalign(output[1])
            shell("{config[binDir]}/read_utils.py index_fasta_picard {output[1]}")
            shell("{config[binDir]}/read_utils.py index_fasta_samtools {output[1]}")
            os.unlink(params.tmpf_muscle)

rule refine_assembly_1:
    ''' This a first pass refinement step where we take the VFAT assembly,
        align all reads back to it, and modify the assembly to the majority
        allele at each position based on read pileups.
        This step now considers both SNPs as well as indels called by GATK
        and will correct the consensus based on GATK calls.
        Reads are aligned with Novoalign with permissive mapping thresholds,
        then PCR duplicates are removed with Picard (in order to debias the
        allele counts in the pileups), and realigned with GATK's
        IndelRealigner (in order to call indels).
        Output FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.fasta',
            config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.cleaned.bam'
    output: config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-deambig.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.bam',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.vcf.gz',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta'
    resources: mem=8
    params: LSF='-W 4:00',
            logid="{sample}",
            novoalign_options = "-r Random -l 30 -g 40 -x 20 -t 502",
            tmpf_intervals = config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.intervals',
            tmpf_bam1 = config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3_pre_rmdup.bam',
            tmpf_bam2 = config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3_pre_indel_realign.bam'
    run:
            update_timestamps(input)
            shell("{config[binDir]}/assembly.py deambig_fasta {input[0]} {output[0]}")
            shell("{config[binDir]}/read_utils.py index_fasta_picard {output[0]}")
            shell("{config[binDir]}/read_utils.py index_fasta_samtools {output[0]}")
            novoalign(input[1], input[0], wildcards.sample, params.tmpf_bam1, options=params.novoalign_options, min_qual=1)
            shell("{config[binDir]}/read_utils.py mkdup_picard {params.tmpf_bam1} {params.tmpf_bam2} --remove --picardOptions CREATE_INDEX=true")
            gatk_local_realign(params.tmpf_bam2, output[0], output[1], params.tmpf_intervals)
            gatk_ug(output[1], output[0], output[2])
            shell("{config[binDir]}/assembly.py vcf_to_fasta {output[2]} {output[3]} --trim_ends --min_coverage 2")
            shell("{config[binDir]}/read_utils.py index_fasta_picard {output[3]}")
            shell("{config[binDir]}/read_utils.py index_fasta_samtools {output[3]}")
            index_novoalign(output[3])
            os.unlink(params.tmpf_bam1)
            os.unlink(params.tmpf_bam2)

rule refine_assembly_2:
    ''' This a second pass refinement step very similar to the first.
        The only differences are that Novoalign mapping parameters are
        more conservative and the input consensus sequence has already
        been refined once and the input reads are the full raw read
        set (instead of the cleaned read set).
        The output of this step is the final assembly for this sample.
        Final FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
            config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.raw.bam'
    output: config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-deambig.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.bam',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.vcf.gz',
            config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
    resources: mem=8
    params: LSF='-W 4:00',
            logid="{sample}",
            novoalign_options = "-r Random -l 40 -g 40 -x 20 -t 100",
            tmpf_intervals = config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.intervals',
            tmpf_bam1 = config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4_pre_rmdup.bam',
            tmpf_bam2 = config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4_pre_indel_realign.bam'
    run:
            update_timestamps(input)
            shell("{config[binDir]}/assembly.py deambig_fasta {input[0]} {output[0]}")
            shell("{config[binDir]}/read_utils.py index_fasta_picard {output[0]}")
            shell("{config[binDir]}/read_utils.py index_fasta_samtools {output[0]}")
            novoalign(input[1], input[0], wildcards.sample, params.tmpf_bam1, options=params.novoalign_options, min_qual=1)
            shell("{config[binDir]}/read_utils.py mkdup_picard {params.tmpf_bam1} {params.tmpf_bam2} --remove --picardOptions CREATE_INDEX=true")
            gatk_local_realign(params.tmpf_bam2, output[0], output[1], params.tmpf_intervals)
            gatk_ug(output[1], output[0], output[2])
            shell("{config[binDir]}/assembly.py vcf_to_fasta {output[2]} {output[3]} --trim_ends --min_coverage 2")
            shell("{config[binDir]}/read_utils.py index_fasta_picard {output[3]}")
            shell("{config[binDir]}/read_utils.py index_fasta_samtools {output[3]}")
            index_novoalign(output[3])
            os.unlink(params.tmpf_bam1)
            os.unlink(params.tmpf_bam2)

rule map_reads_to_self:
    ''' After the final assembly is produced, we also produce BAM files with all reads
        mapped back to its own consensus.  Outputs several BAM files, sorted and indexed:
            {sample}.bam           - all raw reads
            {sample}.mapped.bam    - only mapped reads
            {sample}.rmdup.bam     - only mapped reads, with duplicates removed by Picard
            {sample}.realigned.bam - mapped/rmdup reads, realigned with GATK IndelRealigner
    '''
    input:  config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta',
            config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.raw.bam'
    output: config["dataDir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.bam',
            config["dataDir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.mapped.bam',
            config["dataDir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.rmdup.bam',
            config["dataDir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.realigned.bam'
    resources: mem=4
    params: LSF='-W 4:00',
            logid="{sample}",
            novoalign_options = "-r Random -l 40 -g 40 -x 20 -t 100 -k -c 3",
            tmpf_intervals=config["tmpDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.aligned_to_self.intervals'
    run:
            update_timestamps(input)
            makedirs(os.path.join(config["dataDir"], config["subdirs"]["align_self"]))
            novoalign(input[1], input[0], wildcards.sample, output[0], options=params.novoalign_options)
            filter_bam_mapped_only(output[0], output[1])
            shell("{config[binDir]}/read_utils.py mkdup_picard {output[1]} {output[2]} --remove --picardOptions CREATE_INDEX=true")
            gatk_local_realign(output[2], input[0], output[3], params.tmpf_intervals)
            os.unlink(params.tmpf_intervals)

