"""
    This is a basic framework for depleting human and other contaminant 
    reads from NGS data.  All non-human reads should remain behind.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>'

from snakemake.utils import makedirs

configfile: "config.json"

def read_samples_file(fname):
    with open(fname, 'rt') as inf:
        for line in inf:
            yield line.strip()

rule all_assemble:
    # these are the final desired output files from this pipeline
    input:
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_file"])),
        expand("{dataDir}/{subdir}/{sample}.aligned_to_{sample}.bam",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_file"]))
    params: LSF="-N"
    shell:  "echo all done!"

rule assembly_bam_to_fastq:
    input:  config["dataDir"]+'/'+config["subdirs"]["depletion"]+'/{sample,\w+}.cleaned.bam'
    output: config["tmpDir"] +'/'+config["subdirs"]["assembly"] +'/{sample}.cleaned.1.fastq', 
            config["tmpDir"] +'/'+config["subdirs"]["assembly"] +'/{sample}.cleaned.2.fastq', 
            config["tmpDir"] +'/'+config["subdirs"]["assembly"] +'/{sample}.cleaned.samheader.txt'
    params: LSF='-W 4:00 -M 6 -R "rusage[mem=3]"',
            logid="{sample}"
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["dataDir"],config["tmpDir"]],
                subdir=config["subdirs"]["assembly"]))
            shell("{config[binDir]}/read_utils.py bam_to_fastq {input} {output[0]} {output[1]} --outHeader {output[2]}")

rule trim_reads:
    input:  '{basename}.cleaned.1.fastq', '{basename}.cleaned.2.fastq'
    output: '{basename}.trimmed.1.fastq', '{basename}.trimmed.2.fastq'
    params: LSF='-W 4:00',
            clipDb=config["trim_clipDb"],
            logid="{basename}".split('/')[-1]
    shell:  "{config[binDir]}/taxon_filter.py trim_trimmomatic {input} {output} {params.clipDb}"

rule filter_to_taxon:
    input:  '{basename}.trimmed.{direction}.fastq'
    output: '{basename}.filtered.{direction,[12]}.fastq'
    params: LSF='-W 4:00 -R "rusage[mem=8]" -M 16',
            refDbs=config["lastal_refDb"],
            logid="{basename}-{direction}".split('/')[-1]
    shell:  "{config[binDir]}/taxon_filter.py filter_lastal {input} {params.refDbs} {output}"

rule fix_lastal_output:
    input:  '{basename}.filtered.1.fastq',     '{basename}.filtered.2.fastq'
    output: '{basename}.filtered.fix.1.fastq', '{basename}.filtered.fix.2.fastq'
    params: LSF='-R "rusage[mem=3]" -M 6',
            logid="{basename}".split('/')[-1]
    shell:  "{config[binDir]}/read_utils.py purge_unmated {input} {output}"

rule assemble_trinity:
    input:  '{basename}.filtered.fix.1.fastq', '{basename}.filtered.fix.2.fastq'
    output: '{basename}.assembly1.fasta',
            '{basename}.filtered.fix.sub.1.fastq', '{basename}.filtered.fix.sub.2.fastq',
            '{basename}.trinity'
    params: LSF='-W 4:00 -R "rusage[mem=4]" -M 8',
            logid="{basename}".split('/')[-1]
    # TODO: replace with python wrapper
    #shell:  "{config[binDir]}/consensus.py assemble_trinity {input} {output}"
    shell:  "reuse -q Java-1.6 && " + \
            "/idi/sabeti-scratch/kandersen/bin/scripts/subsampler.py -n 100000 -mode p -in {input} -out {output[1]} {output[2]} && " + \
            "perl /idi/sabeti-scratch/kandersen/bin/trinity_old/Trinity.pl --CPU 1 --min_contig_length 300 --seqType fq --left {output[1]} --right {output[2]} --output {output[3]} && " + \
            "mv {output[3]}/Trinity.fasta {output[0]} && " + \
            "rm -rf {output[1]} {output[2]} {output[3]}"

rule align_and_orient:
    # VFAT / Bellini
    input:  '{basename}.assembly1.fasta',
            '{basename}.filtered.fix.1.fastq', '{basename}.filtered.fix.2.fastq'
    output: '{basename}.assembly2.fasta',
            '{basename}.assembly1.5'
    params: LSF='-W 4:00 -R "rusage[mem=3]" -M 6',
            refGenome=config["ref_genome"],
            logid="{basename}".split('/')[-1]
    # TODO: replace with python wrapper
    #shell:  "{config[binDir]}/consensus.py align_and_orient {input} {params.refGenome} {output}"
    shell:  "touch {output[1]}_merger_assembly.fa && " + \
            "perl /idi/sabeti-scratch/kandersen/bin/VfatSoftwarePackage/orientContig.pl {input}[0] {params.refGenome} {output[1]} && " + \
            "perl /idi/sabeti-scratch/kandersen/bin/VfatSoftwarePackage/contigMerger.pl {output[1]}_orientedContigs {params.refGenome} -readfq {input[1]} -readfq2 {input[2]} -fakequals 30 {output[1]} && " + \
            "cat {output[1]}*assembly.fa > {output[0]} && " + \
            "rm -rf {output[1]}*"

rule sort_contigs:
    # rsealfon script
    input:  '{basename}.assembly2.fasta'
    output: '{basename}.assembly3.fasta', '{basename}.assembly3-bad.fasta'
    params: LSF='-W 4:00 -R "rusage[mem=3]" -M 6',
            length="15000",
            logid="{basename}".split('/')[-1]
    # TODO: replace with python wrapper
    #shell:  "{config[binDir]}/consensus.py sort_and_filter_contigs {input} {output[0]}"
    shell:  "python /idi/sabeti-data/rsealfon/assembly_scripts/filter_short_seqs.py {input} {params.length} {output[1]} {output[0]} && rm {output[1]}"

def index_picard(fasta):
    # TODO: replace with python wrapper
    outfname = fasta[:-6] + '.dict'
    shell("java -Xmx2g -jar /seq/software/picard/current/bin/CreateSequenceDictionary.jar R={fasta} O={outfname}")
def index_samtools(fasta):
    # TODO: replace with python wrapper
    shell("samtools faidx {fasta}")
def index_novoalign(fasta):
    # TODO: replace with python wrapper
    outfname = fasta[:-6] + '.nix'
    shell("/idi/sabeti-scratch/kandersen/bin/novocraft/novoindex {outfname} {fasta}")
def deambig_fasta(inf, outf):
    # TODO: incorporate dpark python code
    shell("python /home/unix/dpark/dev/dpark-scripts/viral.py deambig_fasta {inf} {outf}")
def vcf_to_fasta(inVcf, outFasta, options=""):
    # TODO: incorporate dpark python code
    shell("python /home/unix/dpark/dev/dpark-scripts/viral.py vcf_to_fasta {inVcf} {outFasta} {options}")
def novoalign(reads1, reads2, refFasta, sample_name, outBam, options="-r Random", min_qual=0):
    # TODO: replace with python wrapper
    refFastaIdx = refFasta[:-6] + '.nix'
    cmd = "/idi/sabeti-scratch/kandersen/bin/novocraft_v3/novoalign -f {reads1} {reads2} {options} -F STDFQ -d {refFastaIdx} -o SAM $'@RG\tID:{sample_name}\tSM:{sample_name}\tPL:Illumina\tPU:HiSeq\tLB:BroadPE\tCN:Broad'"
    if min_qual>0:
      cmd += "| samtools view -buS -q {min_qual} - "
    cmd += "| java -Xmx2g -jar /seq/software/picard/current/bin/SortSam.jar SO=coordinate I=/dev/stdin O={outBam} CREATE_INDEX=true VALIDATION_STRINGENCY=SILENT"
    shell(cmd)
def filter_bam_mapped_only(inBam, outBam):
    # TODO: replace with python wrapper
    shell("samtools view -b -q 1 -u {inBam} | java -Xmx2g -jar /seq/software/picard/current/bin/SortSam.jar SO=coordinate I=/dev/stdin O={outBam} CREATE_INDEX=true VALIDATION_STRINGENCY=SILENT")
def picard_rmdup(inBam, outBam):
    # TODO: replace with python wrapper
    shell("java -Xmx2g -jar /seq/software/picard/current/bin/MarkDuplicates.jar I={inBam} O={outBam} CREATE_INDEX=true REMOVE_DUPLICATES=true")
def gatk_ug(inBam, refFasta, outVcf, options="--min_base_quality_score 15 -ploidy 4"):
    # TODO: replace with python wrapper
    shell("java -Xmx2g -jar /humgen/gsa-hpprojects/GATK/bin/current/GenomeAnalysisTK.jar -T UnifiedGenotyper -R {refFasta} -I {inBam} -o {outVcf} {options} --baq OFF --useOriginalQualities -out_mode EMIT_ALL_SITES -dt NONE --num_threads 1 -stand_call_conf 0 -stand_emit_conf 0 -A AlleleBalance")

rule refine_assembly_with_reads:
    input:  config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.cleaned.1.fastq',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.cleaned.2.fastq'
    output: config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.muscle_align.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.muscle_modify.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.muscle_deambig.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.muscle_modify.bam',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.muscle_modify.vcf',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.refined.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.refined_deambig.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.refined.bam',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.refined.vcf'
    params: LSF='-q week -R "rusage[mem=8]" -M 16',
            refGenome=config["ref_genome"], year="2014", refName="zaire_guinea",
            logid="{sample}"
    # TODO: replace with one big python wrapper
    run:
            # tweak Trinity assembly w/muscle alignment to known reference
            shell("cat {input[0]} {params.refGenome} | /idi/sabeti-scratch/kandersen/bin/muscle/muscle -out {output[1]} -quiet")
            shell("python /idi/sabeti-data/rsealfon/assembly_scripts/modified_contig/modify_contig.py -n EBOV_{params.year}_{wildcards.sample} --call-reference-ns yes --trim-ends yes --replace-5ends yes --replace-3ends yes --replace-length 20 --replace-end-gaps yes --remove-end-ns no --call-reference-ambiguous no {output[1]} {output[2]} {params.refName}")
            deambig_fasta(output[2], output[3])
            index_picard(output[2])
            index_novoalign(output[2])
            index_samtools(output[2])
            index_picard(output[3])
            index_samtools(output[3])
            # align sample's reads to its own muscle-modified consensus and replace bases with majority read count
            novoalign(input[1], input[2], output[2], wildcards.sample, output[4], options="-r Random -l 30 -g 40 -x 20 -t 502", min_qual=1)
            gatk_ug(output[4], output[3], output[5])
            vcf_to_fasta(output[5], output[6], options="--trim_ends --min_coverage 2")
            deambig_fasta(output[6], output[7])
            index_picard(output[6])
            index_novoalign(output[6])
            index_samtools(output[6])
            index_picard(output[7])
            index_samtools(output[7])
            # a second pass of align to self and refine
            novoalign(input[1], input[2], output[6], wildcards.sample, output[8], options="-r Random -l 40 -g 40 -x 20 -t 100", min_qual=1)
            gatk_ug(output[8], output[7], output[9])
            vcf_to_fasta(output[9], output[0], options="--trim_ends --min_coverage 2")

rule map_reads_to_assembly:
    input:  config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.cleaned.1.fastq',
            config["tmpDir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.cleaned.2.fastq'
    output: config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.aligned_to_{sample}.bam',
            config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.aligned_to_{sample}.mapped.bam',
            config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.aligned_to_{sample}.rmdup.bam'
    params: LSF='-W 4:00 -R "rusage[mem=4]" -M 8',
            logid="{sample}"
    # TODO: replace with python wrapper
    run:
            index_picard(input[0])
            index_samtools(input[0])
            index_novoalign(input[0])
            novoalign(input[1], input[2], input[0], wildcards.sample, output[0], options="-r Random -l 40 -g 40 -x 20 -t 100 -k -c 3")
            filter_bam_mapped_only(output[0], output[1])
            picard_rmdup(output[1], output[2])
