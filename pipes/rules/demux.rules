"""
    This is a basic framework for demultiplexing viral read data from
    the Broad Institute's walk-up sequencing platform.


    Basically the inputs are:
     - a tabular file describing sample name, library #, run #, barcode1 seq, and barcode2 seq
        for each sample. One such tab file per lane.
     - the flowcell ID and lane number
     - the Bustard directory (ask the person who did the run)
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time, shutil

def read_tab_file(fname):
    with open(fname, 'rt') as inf:
        header = inf.readline().rstrip('\n').split('\t')
        for line in inf:
            yield dict(zip(header, line.rstrip('\n').split('\t')))

def get_bustard_dir(flowcell, lane, runfile):
    lanes = [x for x in read_tab_file(runfile) if x['flowcell']==flowcell and x['lane']==lane]
    assert len(lanes)==1
    return lanes[0]['bustard_dir']

def get_all_samples(runfile):
    samples = set()
    for lane in read_tab_file(runfile):
        for well in read_tab_file(lane['barcode_file']):
            samples.add(well['sample'])
    return list(sorted(samples))

def get_all_libraries(runfile):
    libs = set()
    for lane in read_tab_file(runfile):
        for well in read_tab_file(lane['barcode_file']):
            libs.add(well['sample'] + '.l' + well['library_id_per_sample'])
    return list(sorted(libs))

def get_all_lanes(runfile):
    for lane in read_tab_file(runfile):
        yield '.'.join((lane['flowcell'], lane['lane']))
    
def get_bam_path(lane, well):
    run_id = well['sample']
    if well.get('library_id_per_sample'):
        run_id += '.l' + well['library_id_per_sample']
    if well.get('run_id_per_library'):
        run_id += '.r' + well['run_id_per_library']
    return os.path.join(config['tmpDir'], config['subdirs']['demux'],
        'bams_per_lane', lane['flowcell'] + '.' + lane['lane'],
        run_id + ".bam")

rule make_picard_files:
    input:
            config['seqruns_demux'],
            expand("{run[barcode_file]}", run=read_tab_file(config['seqruns_demux']))
    output:
            expand("{dir}/{file_type}.{lane_id}.txt",
                dir = os.path.join(config['dataDir'], config['subdirs']['demux'], 'inputs'),
                file_type = ['barcodeData','library_params'],
                lane_id = ['.'.join((x['flowcell'],x['lane'])) for x in read_tab_file(config['seqruns_demux'])])
    params: logid="all"
    run:
            dir = os.path.join(config['dataDir'], config['subdirs']['demux'], 'inputs')
            makedirs(dir)
            for lane in read_tab_file(input[0]):
                shell("{config[binDir]}/broad_utils.py make_barcodes_file {lane[barcode_file]} {dir}/barcodeData.{lane[flowcell]}.{lane[lane]}.txt")
                shell("{config[binDir]}/broad_utils.py make_params_file {lane[barcode_file]} {config[tmpDir]}/{config[subdirs][demux]}/bams_per_lane/{lane[flowcell]}.{lane[lane]} {dir}/library_params.{lane[flowcell]}.{lane[lane]}.txt")

rule extract_barcodes:
    input:  config['dataDir']+'/'+config['subdirs']['demux']+'/inputs/barcodeData.{flowcell}.{lane}.txt'
    output: config['tmpDir']+'/'+config['subdirs']['demux']+'/barcodes/{flowcell}.{lane}',
            config['reportsDir']+'/barcodes/barcodes-metrics-{flowcell}.{lane}.txt'
    params: LSF='-R "rusage[mem=16]" -W 4:00 -sp 60',
            logid="{flowcell}.{lane}",
            minimum_base_quality=config["demux_min_baseq"],
            max_mismatches=config["demux_max_mismatches"]
    run:
            makedirs(config['reportsDir']+'/barcodes')
            shutil.rmtree(output[0], ignore_errors=True)
            makedirs(output[0])
            dir = get_bustard_dir(wildcards.flowcell, wildcards.lane, config['seqruns_demux'])
            shell("{config[binDir]}/broad_utils.py extract_barcodes {dir} {wildcards.lane} {input} {output[0]} --outMetrics={output[1]} --max_mismatches={params.max_mismatches} --minimum_base_quality={params.minimum_base_quality}")

rule illumina_basecalls:
    input:  config['dataDir']+'/'+config['subdirs']['demux']+'/inputs/library_params.{flowcell}.{lane}.txt',
            config['tmpDir']+'/'+config['subdirs']['demux']+'/barcodes/{flowcell}.{lane}'
    output: config['tmpDir']+'/'+config['subdirs']['demux']+'/bams_per_lane/{flowcell}.{lane}/Unmatched.bam'
    params: LSF='-R "rusage[mem=64]" -q flower',
            logid="{flowcell}.{lane}",
            outdir=config['tmpDir']+'/'+config['subdirs']['demux']+'/bams_per_lane/{flowcell}.{lane}'
    run:
            shutil.rmtree(params.outdir, ignore_errors=True)
            makedirs(params.outdir)
            dir = get_bustard_dir(wildcards.flowcell, wildcards.lane, config['seqruns_demux'])
            shell("{config[binDir]}/broad_utils.py illumina_basecalls {dir} {input[1]} {wildcards.flowcell} {wildcards.lane} {input[0]} --include_non_pf_reads=false")

def merge_bams_inputs(wildcards):
    for lane in read_tab_file(config['seqruns_demux']):
        for well in read_tab_file(lane['barcode_file']):
            if well['sample']==wildcards.sample and well['library_id_per_sample']==wildcards.library:
                yield get_bam_path(lane, well)

rule merge_bams_demux:
    input:  merge_bams_inputs
    output: config['dataDir']+'/'+config['subdirs']['source']+'/{sample}.l{library}.bam'
    params: LSF='-R "rusage[mem=7]" -W 4:00',
            logid="{sample}.l{library}"
    run:
            makedirs(os.path.join(config['dataDir'], config['subdirs']['source']))
            shell("{config[binDir]}/read_utils.py merge_bams {input} {output} --picardOptions SORT_ORDER=queryname")

